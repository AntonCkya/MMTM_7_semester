# MMTM_7_semester
Лабораторные работы по методам, средствам и технологиям мультимедиа за 7 семестр

Синюков А.С. М8О-406Б-21

# Результаты:

Классификация:

| Алгоритм           | Задача                         | Accuracy |
|--------------------|--------------------------------|----------|
| KNN                | Классификация                  | 0.9824   |
| KNN                | Классификация (улучшенная)     | 0.9494   |
| KNN                | Классификация (самост.)        | 0.9692   |
| KNN                | Классификация (самост. улучш.) | 0.9426   |
| Log/Lin Regression | Классификация                  | 0.9520   |
| Log/Lin Regression | Классификация (улучшенная)     | 0.9666   |
| Log/Lin Regression | Классификация (самост.)        | 0.9520   |
| Log/Lin Regression | Классификация (самост. улучш.) | 0.9666   |
| Decision Tree      | Классификация                  | 0.9449   |
| Decision Tree      | Классификация (улучшенная)     | 0.9518   |
| Decision Tree      | Классификация (самост.)        | 0.97     |
| Decision Tree      | Классификация (самост. улучш.) | 0.935    |
| Random Forest      | Классификация                  | 0.9746   |
| Random Forest      | Классификация (улучшенная)     | 0.9318   |
| Random Forest      | Классификация (самост.)        | 0.9399   |
| Random Forest      | Классификация (самост. улучш.) | 0.9375   |
| Gradient Boosting  | Классификация                  | 0.9525   |
| Gradient Boosting  | Классификация (улучшенная)     | 0.9525   |
| Gradient Boosting  | Классификация (самост.)        | 0.9535   |
| Gradient Boosting  | Классификация (самост. улучш.) | 0.9529   |


Регрессия:

| Алгоритм           | Задача                     |   MAE    |
|--------------------|----------------------------|----------|
| KNN                | Регрессия                  | 1.1822   |
| KNN                | Регрессия (улучшенная)     | 1.0746   |
| KNN                | Регрессия (самост.)        | 1.1825   |
| KNN                | Регрессия (самост. улучш.) | 1.0746   |
| Log/Lin Regression | Регрессия                  | 1.1079   |
| Log/Lin Regression | Регрессия (улучшенная)     | 1.1073   |
| Log/Lin Regression | Регрессия (самост.)        | 1.1064   |
| Log/Lin Regression | Регрессия (самост. улучш.) | 1.1073   |
| Decision Tree      | Регрессия                  | 1.2867   |
| Decision Tree      | Регрессия (улучшенная)     | 1.0915   |
| Decision Tree      | Регрессия (самост.)        | 1.547    |
| Decision Tree      | Регрессия (самост. улучш.) | 1.7692   |
| Random Forest      | Регрессия                  | 1.0094   |
| Random Forest      | Регрессия (улучшенная)     | 1.0683   |
| Random Forest      | Регрессия (самост.)        | 1.3174   |
| Random Forest      | Регрессия (самост. улучш.) | 1.2792   |
| Gradient Boosting  | Регрессия                  | 1.0721   |
| Gradient Boosting  | Регрессия (улучшенная)     | 1.123    |
| Gradient Boosting  | Регрессия (самост.)        | 1.0721   |
| Gradient Boosting  | Регрессия (самост. улучш.) | 1.0786   |


Общие выводы:

1) Задачи, решаемые данными алгоритмами, нетипичны. Хоть и видно высокую accuracy у классификации и небольшое отклонение у регрессии, задачи при таких данных предугадать сложно (в регрессии основными факторами для оценки игры выступали дата выхода, платформа, и "одобрение" игроков (1 или 0), чего явно недостаточно). В некоторых моментах за "высокой" accuracy скрывался нулевой recall, который сигнализировал о том, что модель не выбирает второй класс. У регрессии, хоть и не так заметно, но тоже была тенденция "не лезь в оценки ниже 5".

2) Основной проблемой собственных реализаций, по моему мнению, стало время их работы. Иногда они работали немного лучше, иногда хуже, но всегда дольше. В Decision Tree пришлось срезать датасет до 1000 строк, чтобы модель за адекватное время сделала прогноз. 

3) Самым лучшим решением задачи классификации оказался базовый бейзлайн KNN (какая ирония), а в регрессии - базовый бейзлайн Random Forest. 
